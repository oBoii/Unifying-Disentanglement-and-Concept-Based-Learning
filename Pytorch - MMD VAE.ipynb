{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:12.428519400Z",
     "start_time": "2024-02-08T17:41:12.413712900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on https://github.com/ShengjiaZhao/MMD-Variational-Autoencoder/blob/master/mmd_vae.ipynb\n",
    "# code copied from: https://github.com/napsternxg/pytorch-practice/blob/master/Pytorch%20-%20MMD%20VAE.ipynb\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:12.456511300Z",
     "start_time": "2024-02-08T17:41:12.427515500Z"
    }
   },
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "class Reshape(torch.nn.Module):\n",
    "    def __init__(self, outer_shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.outer_shape = outer_shape\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), *self.outer_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:12.618400500Z",
     "start_time": "2024-02-08T17:41:12.445470700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3200])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_flatten_output():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 64, 4, 2),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Conv2d(64, 128, 4, 2),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        Flatten(),\n",
    "    )\n",
    "    return model(Variable(torch.rand(2,1,28,28))).size()\n",
    "get_flatten_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:12.814044300Z",
     "start_time": "2024-02-08T17:41:12.619481200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 1, 28, 28])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_reshape_output():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(2, 1024),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(1024, 7*7*128),\n",
    "        torch.nn.ReLU(),\n",
    "        Reshape((128,7,7,)),\n",
    "        torch.nn.ConvTranspose2d(128, 64, 4, 2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.ConvTranspose2d(64, 1, 4, 2, padding=3),\n",
    "        torch.nn.Sigmoid()\n",
    "    )\n",
    "    return model(Variable(torch.rand(2,2))).size()\n",
    "get_reshape_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:12.846829Z",
     "start_time": "2024-02-08T17:41:12.821916800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoder and decoder use the DC-GAN architecture\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model = torch.nn.ModuleList([\n",
    "            torch.nn.Conv2d(1, 64, 4, 2, padding=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(64, 128, 4, 2, padding=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            Flatten(),\n",
    "            torch.nn.Linear(6272, 1024),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(1024, z_dim)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"Encoder\")\n",
    "        #print(x.size())\n",
    "        for layer in self.model:\n",
    "            x = layer(x)\n",
    "            #print(x.size())\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.model = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(z_dim, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 7*7*128),\n",
    "            torch.nn.ReLU(),\n",
    "            Reshape((128,7,7,)),\n",
    "            torch.nn.ConvTranspose2d(128, 64, 4, 2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(64, 1, 4, 2, padding=1),\n",
    "            torch.nn.Sigmoid()\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"Decoder\")\n",
    "        #print(x.size())\n",
    "        for layer in self.model:\n",
    "            x = layer(x)\n",
    "            #print(x.size())\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:12.851849Z",
     "start_time": "2024-02-08T17:41:12.833136400Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_kernel(x, y):\n",
    "    x_size = x.size(0)\n",
    "    y_size = y.size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.unsqueeze(1) # (x_size, 1, dim)\n",
    "    y = y.unsqueeze(0) # (1, y_size, dim)\n",
    "    tiled_x = x.expand(x_size, y_size, dim)\n",
    "    tiled_y = y.expand(x_size, y_size, dim)\n",
    "    kernel_input = (tiled_x - tiled_y).pow(2).mean(2)/float(dim)\n",
    "    return torch.exp(-kernel_input) # (x_size, y_size)\n",
    "\n",
    "def compute_mmd(x, y):\n",
    "    x_kernel = compute_kernel(x, x)\n",
    "    y_kernel = compute_kernel(y, y)\n",
    "    xy_kernel = compute_kernel(x, y)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:12.903077600Z",
     "start_time": "2024-02-08T17:41:12.848852500Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = Encoder(z_dim)\n",
    "        self.decoder = Decoder(z_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return z, x_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:12.971691300Z",
     "start_time": "2024-02-08T17:41:12.860377600Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:13.106122900Z",
     "start_time": "2024-02-08T17:41:12.971639600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1, 2]), torch.Size([1, 1, 28, 28]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z, x_reconstructed = model(Variable(torch.rand(1,1,28,28)))\n",
    "z.size(), x_reconstructed.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:13.125491200Z",
     "start_time": "2024-02-08T17:41:13.104120800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert a numpy array of shape [batch_size, height, width, 1] into a displayable array \n",
    "# of shape [height*sqrt(batch_size, width*sqrt(batch_size))] by tiling the images\n",
    "def convert_to_display(samples):\n",
    "    cnt, height, width = int(math.floor(math.sqrt(samples.shape[0]))), samples.shape[1], samples.shape[2]\n",
    "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
    "    samples = np.reshape(samples, [height, cnt, cnt, width])\n",
    "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
    "    samples = np.reshape(samples, [height*cnt, width*cnt])\n",
    "    return samples\n",
    "\n",
    "\n",
    "def train(\n",
    "    dataloader,\n",
    "    z_dim=2,\n",
    "    n_epochs=10,\n",
    "    use_cuda=True,\n",
    "    print_every=100,\n",
    "    plot_every=500\n",
    "):\n",
    "    model = Model(z_dim)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    #print(model)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    i = -1\n",
    "    for epoch in range(n_epochs):\n",
    "        for images, labels in dataloader:\n",
    "            i += 1\n",
    "            optimizer.zero_grad()\n",
    "            x = Variable(images, requires_grad=False)\n",
    "            true_samples = Variable(\n",
    "                torch.randn(200, z_dim),\n",
    "                requires_grad=False\n",
    "            )\n",
    "            if use_cuda:\n",
    "                x = x.cuda()\n",
    "                true_samples = true_samples.cuda()\n",
    "            z, x_reconstructed = model(x)\n",
    "            mmd = compute_mmd(true_samples, z)\n",
    "            nll = (x_reconstructed - x).pow(2).mean()\n",
    "            loss = nll + mmd\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % print_every == 0:\n",
    "                print(\"Negative log likelihood is {:.5f}, mmd loss is {:.5f}\".format(\n",
    "                    nll.data[0], mmd.data[0]))\n",
    "            if i % plot_every == 0:\n",
    "                gen_z = Variable(\n",
    "                    torch.randn(100, z_dim),\n",
    "                    requires_grad=False\n",
    "                )\n",
    "                if use_cuda:\n",
    "                    gen_z = gen_z.cuda()\n",
    "                samples = model.decoder(gen_z)\n",
    "                samples = samples.permute(0,2,3,1).contiguous().cpu().data.numpy()\n",
    "                plt.imshow(convert_to_display(samples), cmap='Greys_r')\n",
    "                plt.show()\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:17.510206900Z",
     "start_time": "2024-02-08T17:41:13.113649800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./tmp/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./tmp/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./tmp/MNIST\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./tmp/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./tmp/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./tmp/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./tmp/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./tmp/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./tmp/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./tmp/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./tmp/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./tmp/MNIST\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=200\n",
    "mnist_train = torch.utils.data.DataLoader(\n",
    "    MNIST(\"./tmp/MNIST\", train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=3,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:24.813524600Z",
     "start_time": "2024-02-08T17:41:17.489819100Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m z_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmnist_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mz_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[11], line 46\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(dataloader, z_dim, n_epochs, use_cuda, print_every, plot_every)\u001B[0m\n\u001B[0;32m     43\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m print_every \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNegative log likelihood is \u001B[39m\u001B[38;5;132;01m{:.5f}\u001B[39;00m\u001B[38;5;124m, mmd loss is \u001B[39m\u001B[38;5;132;01m{:.5f}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m---> 46\u001B[0m         \u001B[43mnll\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m, mmd\u001B[38;5;241m.\u001B[39mdata[\u001B[38;5;241m0\u001B[39m]))\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m plot_every \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     48\u001B[0m     gen_z \u001B[38;5;241m=\u001B[39m Variable(\n\u001B[0;32m     49\u001B[0m         torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m100\u001B[39m, z_dim),\n\u001B[0;32m     50\u001B[0m         requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     51\u001B[0m     )\n",
      "\u001B[1;31mIndexError\u001B[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "z_dim = 2\n",
    "model = train(mnist_train, z_dim=z_dim, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-08T17:41:24.808503800Z"
    }
   },
   "outputs": [],
   "source": [
    "# If latent z is 2-dimensional we visualize it by plotting latent z of different digits in different colors\n",
    "if z_dim == 2:\n",
    "    test_batch_size = 500\n",
    "    mnist_test = torch.utils.data.DataLoader(\n",
    "        MNIST(\"./tmp/MNIST\", train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, num_workers=3,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    z_list, label_list = [], []\n",
    "    for i in range(20):\n",
    "        batch_x, batch_y = iter(mnist_test).next()\n",
    "        batch_x = Variable(batch_x, requires_grad=False).cuda()\n",
    "        z = model.encoder(batch_x)\n",
    "        z_list.append(z.cpu().data.numpy())\n",
    "        label_list.append(batch_y.numpy())\n",
    "    z = np.concatenate(z_list, axis=0)\n",
    "    label = np.concatenate(label_list)\n",
    "    plt.scatter(z[:, 0], z[:, 1], c=label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train on FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T17:41:24.811505500Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=200\n",
    "mnist_train = torch.utils.data.DataLoader(\n",
    "    FashionMNIST(\"./tmp/FashionMNIST\", train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=3,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "z_dim = 2\n",
    "model = train(mnist_train, z_dim=z_dim, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-08T17:41:24.811505500Z"
    }
   },
   "outputs": [],
   "source": [
    "# If latent z is 2-dimensional we visualize it by plotting latent z of different digits in different colors\n",
    "if z_dim == 2:\n",
    "    test_batch_size = 500\n",
    "    mnist_test = torch.utils.data.DataLoader(\n",
    "        FashionMNIST(\"./tmp/FashionMNIST\", train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, num_workers=3,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    z_list, label_list = [], []\n",
    "    for i in range(20):\n",
    "        batch_x, batch_y = iter(mnist_test).next()\n",
    "        batch_x = Variable(batch_x, requires_grad=False).cuda()\n",
    "        z = model.encoder(batch_x)\n",
    "        z_list.append(z.cpu().data.numpy())\n",
    "        label_list.append(batch_y.numpy())\n",
    "    z = np.concatenate(z_list, axis=0)\n",
    "    label = np.concatenate(label_list)\n",
    "    plt.scatter(z[:, 0], z[:, 1], c=label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:41:24.827623600Z",
     "start_time": "2024-02-08T17:41:24.815513800Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
